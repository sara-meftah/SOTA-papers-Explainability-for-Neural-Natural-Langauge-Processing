# Tracking SOTA papers about Explainability for Neural Natural Langauge Processing


#### [Surveys](#content)
1. **A Survey on Explainability in Machine Reading Comprehension.** - 2020 - Arxiv [paper](https://arxiv.org/abs/2010.00389)
2. **A Diagnostic Study of Explainability Techniques for Text Classification.** - 2020 - Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing [paper](https://aclanthology.org/2020.emnlp-main.263.pdf) 
3. **A Survey of the State of Explainable AI for Natural Language Processing.** - 2020 - AACL 2020 [paper](https://arxiv.org/abs/2010.00711) [site](https://xainlp2020.github.io/xainlp/)

#### [Evaluation](#content)

1. **The Eval4NLP Shared Task on Explainable Quality Estimation: Overview and Results.** - 2021 - Proceedings of the 2nd Workshop on Evaluation and Comparison of NLP Systems [paper](https://aclanthology.org/2021.eval4nlp-1.17.pdf)
2. **Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?** - 2020 - Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics [paper](https://aclanthology.org/2020.acl-main.491.pdf) [code](https://github.com/peterbhase/InterpretableNLP-ACL2020)
3. **Measuring and Improving Faithfulness of Attention in Neural Machine Translation** - 2021 - Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics [paper](https://aclanthology.org/2021.eacl-main.243.pdf)
4. **Evaluating Explanation Methods for Neural Machine Translation** - 2020 - Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics [paper](https://aclanthology.org/2020.acl-main.35.pdf)



#### [Datasets](#content)

1. **HOTPOTQA: A Dataset for Diverse, Explainable Multi-hop Question Answering.** - 2018 - Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing [paper](https://aclanthology.org/D18-1259/) [data](https://hotpotqa.github.io/)
2. **QUACKIE: A NLP Classification Task With Ground Truth Explanations.** - 2020 - Arxiv [paper](https://aclanthology.org/D18-1259/) [code](https://github.com/axa-rev-research/quackie)  [site](https://axa-rev-research.github.io/quackie/)

#### [Local Interpretable Model-agnostic Explanations (LIME)](#content)

1. **An analysis of lime for text data.** - 2021 - Proceedings of the 24th International Conference on Artificial Intelligence and Statistics (AISTATS) 2021 [paper](http://proceedings.mlr.press/v130/mardaoui21a/mardaoui21a.pdf) 
2. **Explaining the explainer: A first theoretical analysis of LIME.** - 2020 - Proceedings of the 23th International Conference on Artificial Intelligence and Statistics (AISTATS) 2020 [paper](http://proceedings.mlr.press/v108/garreau20a/garreau20a.pdf) 
3. **Deterministic Local Interpretable Model-Agnostic Explanations for Stable Explainability.** - 2021 - Special Issue Advances in Explainable Artificial Intelligence (XAI) [paper](https://aclanthology.org/D18-1259/) [code](https://www.mdpi.com/2504-4990/3/3/27/htm)  [site](https://github.com/rehmanzafar/dlime_experiments)

#### [Supervised Explainability](#content)
1. **Training Classifiers with Natural Language Explanations** - 2018 - Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics [paper](https://aclanthology.org/P18-1175.pdf) 
2. **e-SNLI: Natural Language Inference with Natural Language Explanations** - 2018 - 32nd Conference on Neural Information Processing Systems (NeurIPS 2018) [paper](https://papers.nips.cc/paper/2018/file/4c7a167bb329bd92580a99ce422d6fa6-Paper.pdf) [code](https://github.com/OanaMariaCamburu/e-SNLI) 
3. **Measuring Association Between Labels and Free-Text Rationales** - 2021 - EMNLP 2021 [paper](https://arxiv.org/pdf/2010.12762.pdf) [code](https://github.com/allenai/label_rationale_association) 


#### [Anchors](#content)
1. **Anchors: High-Precision Model-Agnostic Explanations** - 2018 - AAAI Conference on Artificial Intelligence (AAAI) [paper](https://homes.cs.washington.edu/~marcotcr/aaai18.pdf) [code](https://github.com/marcotcr/anchor) 


#### [Gradient-based explanations](#content)
1. **Gradient-based Analysis of NLP Models is Manipulable** - 2020 - Findings of the Association for Computational Linguistics: EMNLP 2020 [paper](https://aclanthology.org/2020.findings-emnlp.24.pdf) [code](https://github.com/ucinlp/facade/tree/facade) [site](https://ucinlp.github.io/facade/) 

