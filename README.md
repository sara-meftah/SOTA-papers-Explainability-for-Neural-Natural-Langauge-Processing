# Tracking SOTA papers about Explainability for Neural Natural Langauge Processing


#### [Surveys](#content)
1. **A Survey on Explainability in Machine Reading Comprehension.** - 2020 - Arxiv [paper](https://arxiv.org/abs/2010.00389)
2. **A Diagnostic Study of Explainability Techniques for Text Classification.** - 2020 - Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing [paper](https://aclanthology.org/2020.emnlp-main.263.pdf) 
3. **A Survey of the State of Explainable AI for Natural Language Processing.** - 2020 - AACL 2020 [paper](https://arxiv.org/abs/2010.00711) [site](https://xainlp2020.github.io/xainlp/)
4. **( Not NLP) Evaluating the Quality of Machine Learning Explanations: A Survey on Methods and Metrics** - 2021 - MDPI [paper](https://www.mdpi.com/2079-9292/10/5/593)  



#### [Evaluation](#content)

1. **The Eval4NLP Shared Task on Explainable Quality Estimation: Overview and Results.** - 2021 - Proceedings of the 2nd Workshop on Evaluation and Comparison of NLP Systems [paper](https://aclanthology.org/2021.eval4nlp-1.17.pdf)
2. **Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?** - 2020 - Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics [paper](https://aclanthology.org/2020.acl-main.491.pdf) [code](https://github.com/peterbhase/InterpretableNLP-ACL2020)
3. **Measuring and Improving Faithfulness of Attention in Neural Machine Translation** - 2021 - Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics [paper](https://aclanthology.org/2021.eacl-main.243.pdf)
4. **Evaluating Explanation Methods for Neural Machine Translation** - 2020 - Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics [paper](https://aclanthology.org/2020.acl-main.35.pdf)
5. **( Not NLP) On the (In)fidelity and Sensitivity of Explanations** - 2019 - 33rd Conference on Neural Information Processing Systems (NeurIPS 2019) [paper](https://papers.nips.cc/paper/2019/file/a7471fdc77b3435276507cc8f2dc2569-Paper.pdf)  [code](https://github.com/chihkuanyeh/saliency_evaluation)
6. **( Not NLP) What Do You See? Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors** - 2021 - KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining [paper](https://dl.acm.org/doi/10.1145/3447548.3467213)  




#### [Datasets](#content)

1. **HOTPOTQA: A Dataset for Diverse, Explainable Multi-hop Question Answering.** - 2018 - Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing [paper](https://aclanthology.org/D18-1259/) [data](https://hotpotqa.github.io/)
2. **QUACKIE: A NLP Classification Task With Ground Truth Explanations.** - 2020 - Arxiv [paper](https://aclanthology.org/D18-1259/) [code](https://github.com/axa-rev-research/quackie)  [site](https://axa-rev-research.github.io/quackie/)

#### [Local Interpretable Model-agnostic Explanations (LIME)](#content)

1. **An analysis of lime for text data.** - 2021 - Proceedings of the 24th International Conference on Artificial Intelligence and Statistics (AISTATS) 2021 [paper](http://proceedings.mlr.press/v130/mardaoui21a/mardaoui21a.pdf) 
2. **Explaining the explainer: A first theoretical analysis of LIME.** - 2020 - Proceedings of the 23th International Conference on Artificial Intelligence and Statistics (AISTATS) 2020 [paper](http://proceedings.mlr.press/v108/garreau20a/garreau20a.pdf) 
3. **Deterministic Local Interpretable Model-Agnostic Explanations for Stable Explainability.** - 2021 - Special Issue Advances in Explainable Artificial Intelligence (XAI) [paper](https://aclanthology.org/D18-1259/) [code](https://www.mdpi.com/2504-4990/3/3/27/htm)  [site](https://github.com/rehmanzafar/dlime_experiments)

#### [Supervised Rationalization](#content)

1. **Using “annotator rationales” to improve machine learning for text categorization** - 2007 - Human language technologies 2007: The conference of the North American chapter of the association for computational linguistics (NAACL 2007) [paper](https://aclanthology.org/N07-1033/) 
2. **Rationale-Augmented Convolutional Neural Networks for Text Classification** - 2016 - Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing [paper](https://aclanthology.org/D16-1076/)  [official code](https://github.com/bwallace/rationale-CNN)  [other implementation](https://github.com/yezhang-xiaofan/Rationale-CNN) 
3. **Training Classifiers with Natural Language Explanations** - 2018 - Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics [paper](https://aclanthology.org/P18-1175.pdf) 
4. **e-SNLI: Natural Language Inference with Natural Language Explanations** - 2018 - 32nd Conference on Neural Information Processing Systems (NeurIPS 2018) [paper](https://papers.nips.cc/paper/2018/file/4c7a167bb329bd92580a99ce422d6fa6-Paper.pdf) [code](https://github.com/OanaMariaCamburu/e-SNLI) 
5. **Measuring Association Between Labels and Free-Text Rationales** - 2021 - EMNLP 2021 [paper](https://arxiv.org/pdf/2010.12762.pdf) [code](https://github.com/allenai/label_rationale_association) 

#### [Unsupervised Rationalization](#content)

1. **Rationalizing Neural Predictions** - 2016 - Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing [paper](https://aclanthology.org/D16-1011.pdf) [official code](https://github.com/taolei87/rcnn) 
2. **Rethinking Cooperative Rationalization: Introspective Extraction and Complement Control** - 2019 - Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing [paper](https://arxiv.org/pdf/1910.13294.pdf)  [official code](https://github.com/Gorov/three_player_for_emnlp) 
3. **Learning to Faithfully Rationalize by Construction** - 2020 - Proceedings of the Association for Computational Linguistics (ACL) [paper](https://aclanthology.org/2020.acl-main.409.pdf)  [official code](https://github.com/successar/FRESH) 


#### [Anchors](#content)
1. **Anchors: High-Precision Model-Agnostic Explanations** - 2018 - AAAI Conference on Artificial Intelligence (AAAI) [paper](https://homes.cs.washington.edu/~marcotcr/aaai18.pdf) [code](https://github.com/marcotcr/anchor) 


#### [Gradient-based explanations](#content)
1. **Gradient-based Analysis of NLP Models is Manipulable** - 2020 - Findings of the Association for Computational Linguistics: EMNLP 2020 [paper](https://aclanthology.org/2020.findings-emnlp.24.pdf) [code](https://github.com/ucinlp/facade/tree/facade) [site](https://ucinlp.github.io/facade/) 

#### [Knowledge Destillation](#content)
1. **Born-Again Neural Networks** - 2018 - Proceedings of the 35 th International Conference on Machine Learning [paper](https://proceedings.mlr.press/v80/furlanello18a/furlanello18a.pdf) [code](https://github.com/nocotan/born_again_neuralnet)


#### [Counterfactual explanations](#content)
1. **Counterfactual Memorization in Neural Language Models** - 2021 - Arxiv [paper](https://arxiv.org/abs/2112.12938)
2. **CausaLM: Causal Model Explanation Through Counterfactual Language Models** - 2021 - Computational Linguistics (2021) [paper](https://direct.mit.edu/coli/article/47/2/333/98518/CausaLM-Causal-Model-Explanation-Through) [code](https://github.com/amirfeder/CausaLM) [data](https://www.kaggle.com/amirfeder/causalm) 





